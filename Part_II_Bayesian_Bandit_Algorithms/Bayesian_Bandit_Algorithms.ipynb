{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Bayesian Bandit Algorithms\n",
    "There are two arms which may be pulled repeatedly in any order.\n",
    "Each pull may result in either a success or a failure.\n",
    "The sequence of successes and failures which results from pulling arm $i$ ($i \\in \\{1, 2\\}$) forms a Bernoulli process with unknown success probability $\\theta_{i}$.\n",
    "A success at the $t^{th}$ pull yields a reward $\\gamma^{t-1}$ ($0 < \\gamma <1$), while an unsuccessful pull yields a zero reward.\n",
    "At time zero, each $\\theta_{i}$ has a Beta prior distribution with two parameters $\\alpha_{i}, \\beta_{i}$ and these distributions are independent for different arms.\n",
    "These prior distributions are updated to posterior distributions as arms are pulled.\n",
    "Since the class of Beta distributions is closed under Bernoulli sampling, posterior distributions are all Beta distributions.\n",
    "How should the arm to pull next in each time slot be chosen to maximize the total expected reward from an infinite sequence of pulls?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. \tOne intuitive policy suggests that in each time slot we should pull the arm for which the current expected value of $\\theta_{i}$ is the largest. This policy behaves very good in most cases. Please design simulations to check the behavior of this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.1, alpha: [1, 1], beta: [1, 1], avg_reward: 0.5534, avg_regret_rate: 0.2794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.1, alpha: [2, 1], beta: [1, 1], avg_reward: 0.5405, avg_regret_rate: 0.2721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.1, alpha: [20, 1], beta: [10, 1], avg_reward: 0.5649, avg_regret_rate: 0.2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 53.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.3, alpha: [1, 1], beta: [1, 1], avg_reward: 0.7975, avg_regret_rate: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 48.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.3, alpha: [2, 1], beta: [1, 1], avg_reward: 0.7813, avg_regret_rate: 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 50.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.3, alpha: [20, 1], beta: [10, 1], avg_reward: 0.6766, avg_regret_rate: 0.2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5, alpha: [1, 1], beta: [1, 1], avg_reward: 1.0809, avg_regret_rate: 0.1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 50.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5, alpha: [2, 1], beta: [1, 1], avg_reward: 1.0306, avg_regret_rate: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5, alpha: [20, 1], beta: [10, 1], avg_reward: 0.9873, avg_regret_rate: 0.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.7, alpha: [1, 1], beta: [1, 1], avg_reward: 2.0485, avg_regret_rate: 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.7, alpha: [2, 1], beta: [1, 1], avg_reward: 1.8086, avg_regret_rate: 0.2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 50.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.7, alpha: [20, 1], beta: [10, 1], avg_reward: 1.6074, avg_regret_rate: 0.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 53.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.9, alpha: [1, 1], beta: [1, 1], avg_reward: 6.2194, avg_regret_rate: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.9, alpha: [2, 1], beta: [1, 1], avg_reward: 6.0296, avg_regret_rate: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.9, alpha: [20, 1], beta: [10, 1], avg_reward: 5.4094, avg_regret_rate: 0.2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.99, alpha: [1, 1], beta: [1, 1], avg_reward: 61.6180, avg_regret_rate: 0.0568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 53.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.99, alpha: [2, 1], beta: [1, 1], avg_reward: 64.7995, avg_regret_rate: 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 53.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.99, alpha: [20, 1], beta: [10, 1], avg_reward: 61.9752, avg_regret_rate: 0.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def intuitive_policy(N, gamma, true_theta, alpha, beta):\n",
    "    \"\"\"\n",
    "    Implements the intuitive policy for a two-armed bandit problem with discounted rewards.\n",
    "    \n",
    "    Args:\n",
    "        N (int): Number of time steps\n",
    "        gamma (float): Discount factor\n",
    "        true_theta (np.ndarray): True probabilities for each arm\n",
    "        alpha (list): Initial alpha parameters for Beta distribution\n",
    "        beta (list): Initial beta parameters for Beta distribution\n",
    "    \n",
    "    Returns:\n",
    "        float: Sum of discounted rewards\n",
    "    \"\"\"\n",
    "    rewards = np.zeros(N)\n",
    "    alpha = np.array(alpha)  \n",
    "    beta = np.array(beta)\n",
    "\n",
    "    for t in range(N):\n",
    "        theta_estimate = alpha / (alpha + beta)\n",
    "        chosen_arm = np.argmax(theta_estimate)\n",
    "\n",
    "        reward = np.random.rand() < true_theta[chosen_arm]\n",
    "        rewards[t] = reward * (gamma ** t)\n",
    "        \n",
    "        alpha[chosen_arm] += reward\n",
    "        beta[chosen_arm] += 1 - reward\n",
    "\n",
    "    return np.sum(rewards)\n",
    "\n",
    "num_trials = 200\n",
    "N = 5000\n",
    "gamma_list = [0.1, 0.3, 0.5, 0.7, 0.9, 0.99]\n",
    "alpha_list = [[1, 1], [2, 1], [20, 1]]\n",
    "beta_list = [[1, 1], [1, 1], [10, 1]]\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    for alpha, beta in zip(alpha_list, beta_list):\n",
    "        rewards = np.zeros(num_trials)\n",
    "        regret_rate = np.zeros(num_trials)\n",
    "        \n",
    "        for i in tqdm(range(num_trials)):\n",
    "            true_theta = np.random.rand(2)\n",
    "\n",
    "            rewards[i] = intuitive_policy(N, gamma, true_theta, alpha, beta)\n",
    "            max_value = np.max(true_theta) / (1 - gamma)\n",
    "            regret_rate[i] = 1 - rewards[i] / max_value\n",
    "            \n",
    "        print(f\"gamma: {gamma}, alpha: {alpha}, beta: {beta}, \"\n",
    "              f\"avg_reward: {np.mean(rewards):.4f}, \"\n",
    "              f\"avg_regret_rate: {np.mean(regret_rate):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the algorithm, we need to find a suitable metric. Regret seems to be a good choice, but it is not normalized, leading to different scales for different settings. (For example, larger $\\gamma$ leads to larger regret.) Thus, we use the regret rate, which shows the portion of regret to the maximum expected reward.   \n",
    "The regret rate is defined as follow:  \n",
    "\n",
    "$\\text{regret rate} = 1 - \\frac{Reward}{\\max_i \\theta_i/(1-\\gamma)}$\n",
    "\n",
    "where the maximum possible reward is achieved by always pulling the arm with the highest true probability. For the discounted setting, this equals $\\frac{\\max_i \\theta_i}{1-\\gamma}$.\n",
    "\n",
    "The simulation results show that the intuitive policy performs well in most cases, achieving low regret rates.  \n",
    "| γ | Prior (α, β) | Average Reward | Average Regret Rate |\n",
    "|---|-------------|----------------|-------------------|\n",
    "| 0.1 | [1,1], [1,1] | 0.5534 | 0.2794 |\n",
    "| 0.1 | [2,1], [1,1] | 0.5405 | 0.2721 |\n",
    "| 0.1 | [20,1], [10,1] | 0.5649 | 0.2339 |\n",
    "| 0.3 | [1,1], [1,1] | 0.7975 | 0.1243 |\n",
    "| 0.3 | [2,1], [1,1] | 0.7813 | 0.2369 |\n",
    "| 0.3 | [20,1], [10,1] | 0.6766 | 0.2897 |\n",
    "| 0.5 | [1,1], [1,1] | 1.0809 | 0.1999 |\n",
    "| 0.5 | [2,1], [1,1] | 1.0306 | 0.2144 |\n",
    "| 0.5 | [20,1], [10,1] | 0.9873 | 0.2047 |\n",
    "| 0.7 | [1,1], [1,1] | 2.0485 | 0.1281 |\n",
    "| 0.7 | [2,1], [1,1] | 1.8086 | 0.2016 |\n",
    "| 0.7 | [20,1], [10,1] | 1.6074 | 0.2460 |\n",
    "| 0.9 | [1,1], [1,1] | 6.2194 | 0.0916 |\n",
    "| 0.9 | [2,1], [1,1] | 6.0296 | 0.0888 |\n",
    "| 0.9 | [20,1], [10,1] | 5.4094 | 0.2213 |\n",
    "| 0.99 | [1,1], [1,1] | 61.6180 | 0.0568 |\n",
    "| 0.99 | [2,1], [1,1] | 64.7995 | 0.0434 |\n",
    "| 0.99 | [20,1], [10,1] | 61.9752 | 0.1035 |\n",
    "\n",
    "This can be attributed to several factors:\n",
    "\n",
    "1. **Efficient Exploration**: The policy naturally balances exploration and exploitation through Bayesian updating of the Beta distributions.\n",
    "\n",
    "2. **Prior Knowledge Integration**: The Beta distribution parameters (α, β) allow incorporating prior knowledge about the arms, which helps guide initial exploration.\n",
    "\n",
    "3. **Quick Convergence**: As more rewards are observed, the posterior distributions quickly concentrate around the true probabilities, leading to optimal arm selection.\n",
    "\n",
    "Looking at the simulation results across different discount factors (γ) and prior parameters (α, β), we see consistently low regret rates, indicating the policy's robustness to different parameter settings. However, as we'll see in the counter-example, there are specific scenarios where this policy can be suboptimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. However, such intuitive policy is unfortunately not optimal. Please provide an example to show why such policy is not optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 38.13\n",
      "Maximum possible reward: 80.00\n",
      "Regret rate: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Here's a counter-example with a strongly biased prior, but the second arm is actually better.\n",
    "# We'll run fewer steps (N_short=100), so the policy doesn't have time to correct the prior bias.\n",
    "\n",
    "test_runs = 1000\n",
    "test_rewards = np.zeros(test_runs)\n",
    "N_short = 100\n",
    "gamma_close_to_1 = 0.99\n",
    "\n",
    "\n",
    "counter_alpha = [200, 1]\n",
    "counter_beta = [1, 1]\n",
    "counter_true_theta = np.array([0.6, 0.8])  # second arm has higher probability\n",
    "\n",
    "for i in range(test_runs):\n",
    "    local_alpha = counter_alpha.copy()\n",
    "    local_beta = counter_beta.copy()\n",
    "    test_rewards[i] = intuitive_policy(N_short, gamma_close_to_1, counter_true_theta, local_alpha, local_beta)\n",
    "\n",
    "avg_r = np.mean(test_rewards)\n",
    "optimal_r = np.max(counter_true_theta) / (1 - gamma_close_to_1)\n",
    "print(f\"Average reward: {avg_r:.2f}\")\n",
    "print(f\"Maximum possible reward: {optimal_r:.2f}\")\n",
    "print(f\"Regret rate: {1 - avg_r/optimal_r:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two arms with prior distributions:  \n",
    "#### Arm1  Beta(200,1), suggesting an expected value close to 1.0\n",
    "#### Arm2  Beta(1,1), suggesting an expected value close to 0.5\n",
    "\n",
    "A greedy strategy that consistently favors the arm with the higher expected value may lead to repeatedly selecting Arm 1. However, this approach has critical flaws. The prior for Arm 2 suggests significant uncertainty, as the Beta(1, 1) distribution is essentially non-informative, assigning equal probability to all values between 0 and 1.\n",
    "\n",
    "By selecting Arm 2 more frequently, we can reduce this uncertainty and potentially uncover a true value for Arm 2 that exceeds that of Arm 1.\n",
    "\n",
    "Focusing exclusively on Arm 1 due to its higher initial expected value neglects the possibility that Arm 2 could ultimately provide greater rewards once more data is collected. Failing to explore Arm 2 adequately risks missing out on higher returns that could arise if its true value is found to be higher than initially estimated.\n",
    "\n",
    "When priors differ significantly in terms of uncertainty, a strategy that relies solely on expected values can lead to consistently selecting a suboptimal arm. It is crucial to strike a balance between exploiting known information and exploring uncertain but potentially more rewarding alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. For the expected total reward under an optimal policy, show that the following recurrence equation holds:\n",
    "\n",
    "\\begin{equation*}\n",
    "\t\t\\begin{aligned}\n",
    "\t\t\tR_{1}(\\alpha_{1},\\beta_{1}) \n",
    "\t\t\t= & \\frac{\\alpha_{1}}{\\alpha_{1}+\\beta_{1}} [1+\\gamma R(\\alpha_{1} + 1, \\beta_{1}, \\alpha_{2}, \\beta_{2})] \\\\\n",
    "\t\t\t\t& + \\frac{\\beta_{1}}{\\alpha_{1} + \\beta_{1}} [\\gamma R(\\alpha_{1}, \\beta_{1} + 1, \\alpha_{2}, \\beta_{2})]; \\\\\n",
    "\t\t\tR_{2}(\\alpha_{2}, \\beta_{2}) \n",
    "\t\t\t= & \\frac{\\alpha_{2}}{\\alpha_{2} + \\beta_{2}} [1 + \\gamma R(\\alpha_{1}, \\beta_{1}, \\alpha_{2} + 1, \\beta_{2})] \\\\\n",
    "\t\t\t\t& + \\frac{\\beta_{2}}{\\alpha_{2} + \\beta_{2}} [\\gamma R(\\alpha_{1}, \\beta_{1}, \\alpha_{2}, \\beta_{2} + 1)]; \\\\\n",
    "\t\t\tR(\\alpha_{1}, \\beta_{1}, \\alpha_{2}, \\beta_{2}) \n",
    "\t\t\t= & \\max \\left\\{ R_{1}(\\alpha_{1}, \\beta_{1}), R_{2}(\\alpha_{2}, \\beta_{2}) \\right\\}.\n",
    "\t\t\\end{aligned}  \t\n",
    "\t\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first consider the case of pulling arm 1\n",
    "\n",
    "When pulling arm 1:\n",
    "- Success occurs with probability $\\frac{\\alpha_1}{\\alpha_1+\\beta_1}$ (mean of Beta distribution)\n",
    "    - Immediate reward: 1\n",
    "\n",
    "Since its Bayesian Inferece, with Beta-Binoimal conjugate, so the posterior distribution of $\\theta_1$ is still a Beta distribution, The future expected reward, considering a success, updates the parameters to $Beta(\\alpha_1+1,\\beta_1)$ and $Beta(\\alpha_1,\\beta_1 + 1)$ considering failure.\n",
    "\n",
    "So the next steps' rewards is $R(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)$ when success at this time, and $R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)$ when failure at this time.\n",
    "\n",
    "Since at the $t^{th}$ pull yields a reward $\\gamma^{t-1}$ ($0 < \\gamma <1$), which means that the future's reward is will recieve a discount $\\gamma$ for each time.\n",
    "\n",
    "#### Considering a sucess at this time\n",
    "So for this time, if it sucess, we can recieve the reward $1$. And the parameters become $(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)$ due to the Beta-Binoimal conjugate. After the discount, the future's reward is $\\gamma R(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)$.\n",
    "\n",
    "Also, since success happens with probability $\\theta_1$. So the total rewards when success at this time is $$\\theta_1[1+\\gamma R(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)]$$\n",
    "\n",
    "#### Considering a failure at this time\n",
    "For this time, if it fail, we can recieve the reward $0$. And the parameters become $(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)$ due to the Beta-Binoimal conjugate. After the discount, the future's reward is $0+\\gamma R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)$.\n",
    "\n",
    "Also, since failure happens with probability $1-\\theta_1$. So the total rewards when success at this time is $$(1-\\theta_1)[0+\\gamma R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)]=(1-\\theta_1)[\\gamma R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)]$$\n",
    "\n",
    "So combine the two parts, we can get that the total rewards when pull the first arm is that \n",
    "$$R_1(\\alpha_1,\\beta_1)=\\theta_1[1+\\gamma R(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)]+(1-\\theta_1)[\\gamma R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)]$$\n",
    "\n",
    "$$R_1(\\alpha_1,\\beta_1)=\\dfrac{\\alpha_1}{\\alpha_1+\\beta_1}[1+\\gamma R(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)]+\\dfrac{\\beta_1}{\\alpha_1+\\beta_1}[\\gamma R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)]$$\n",
    "\n",
    "### Similar Reasoning for Arm 2:\n",
    "The expected reward for pulling arm 2 follows the same logic, adjusting for the parameters of arm 2:\n",
    "\n",
    "Similarly, since $$\\theta_2\\sim Beta(\\alpha_2,\\beta_2)$$\n",
    "So with the same method above, we can get that:\n",
    "$$R_2(\\alpha_2,\\beta_2)=\\dfrac{\\alpha_2}{\\alpha_2+\\beta_2}[1+\\gamma R(\\alpha_1,\\beta_1,\\alpha_2+1,\\beta_2)]+\\dfrac{\\beta_2}{\\alpha_2+\\beta_2}[\\gamma R(\\alpha_2,\\beta_1,\\alpha_2,\\beta_2+1)]$$\n",
    "\n",
    "And since we want to maximize the total reward, so we can get that:\n",
    "$$R(\\alpha_1,\\beta_1,\\alpha_2,\\beta_2)=\\max\\{R_1(\\alpha_1,\\beta_1),R_2(\\alpha_2,\\beta_2)\\}$$\n",
    "\n",
    "So above all, the following recurrence equation holds have been proven.\n",
    "$$R_1(\\alpha_1,\\beta_1)=\\dfrac{\\alpha_1}{\\alpha_1+\\beta_1}[1+\\gamma R(\\alpha_1+1,\\beta_1,\\alpha_2,\\beta_2)]+\\dfrac{\\beta_1}{\\alpha_1+\\beta_1}[\\gamma R(\\alpha_1,\\beta_1+1,\\alpha_2,\\beta_2)]$$\n",
    "$$R_2(\\alpha_2,\\beta_2)=\\dfrac{\\alpha_2}{\\alpha_2+\\beta_2}[1+\\gamma R(\\alpha_1,\\beta_1,\\alpha_2+1,\\beta_2)]+\\dfrac{\\beta_2}{\\alpha_2+\\beta_2}[\\gamma R(\\alpha_2,\\beta_1,\\alpha_2,\\beta_2+1)]$$\n",
    "$$R(\\alpha_1,\\beta_1,\\alpha_2,\\beta_2)=\\max\\{R_1(\\alpha_1,\\beta_1),R_2(\\alpha_2,\\beta_2)\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 For the above equations, our solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the recursive equations, we use an approximate method since solving them exactly is impractical due to the infinite number of states and the absence of clear boundaries. In our approach, we introduce a counter to track the number of times each arm has been pulled. Once the counter exceeds 100 pulls, we assume that the exploration phase has provided sufficient information about the arms. At this point, we transition to the exploitation phase, where we choose the arm with the higher mean value. The mean for each arm is computed as $ \\frac{\\alpha}{\\alpha + \\beta} $, based on its Beta distribution parameters.\n",
    "\n",
    "To enhance efficiency, we implement a small optimization by using a dictionary to store the results of states that have already been calculated. This prevents redundant computations and accelerates the process significantly, as many states are encountered repeatedly. This optimization is conceptually similar to memoization in dynamic programming, where previously computed results are reused to avoid recalculating them. By adopting this approach, we strike a balance between exploration and exploitation, while also improving the computational efficiency of our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cache = {}\n",
    "policy = {}\n",
    "\n",
    "def calculate_R(alpha1, beta1, alpha2, beta2, discount_factor, exploration_count, max_exploration = 100):\n",
    "    if (alpha1, beta1, alpha2, beta2) in results_cache:\n",
    "        return results_cache[(alpha1, beta1, alpha2, beta2)]\n",
    "\n",
    "    if exploration_count > max_exploration:\n",
    "        mean_arm1 = alpha1 / (alpha1 + beta1)\n",
    "        mean_arm2 = alpha2 / (alpha2 + beta2)\n",
    "        results_cache[(alpha1, beta1, alpha2, beta2)] = max(mean_arm1, mean_arm2)\n",
    "        policy[(alpha1, beta1, alpha2, beta2)] = mean_arm1 > mean_arm2\n",
    "        return max(mean_arm1, mean_arm2) \n",
    "\n",
    "    expected_reward_arm1 = (\n",
    "        (alpha1 / (alpha1 + beta1)) * (1 + discount_factor * calculate_R(alpha1 + 1, beta1, alpha2, beta2, discount_factor, exploration_count + 1))\n",
    "        + (beta1 / (alpha1 + beta1)) * (discount_factor * calculate_R(alpha1, beta1 + 1, alpha2, beta2, discount_factor, exploration_count + 1))\n",
    "    )\n",
    "\n",
    "    expected_reward_arm2 = (\n",
    "        (alpha2 / (alpha2 + beta2)) * (1 + discount_factor * calculate_R(alpha1, beta1, alpha2 + 1, beta2, discount_factor, exploration_count + 1))\n",
    "        + (beta2 / (alpha2 + beta2)) * (discount_factor * calculate_R(alpha1, beta1, alpha2, beta2 + 1, discount_factor, exploration_count + 1))\n",
    "    )\n",
    "\n",
    "    max_reward = max(expected_reward_arm1, expected_reward_arm2)\n",
    "\n",
    "    results_cache[(alpha1, beta1, alpha2, beta2)] = max_reward\n",
    "    policy[(alpha1, beta1, alpha2, beta2)] = expected_reward_arm1 > expected_reward_arm2\n",
    "\n",
    "    return max_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above contains our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible solution is by using Q-Learning. As we can regard $R_1$ and $R_2$ as the Q-value of the state, and $R$ as the value of the state, the problem is actually a Markov Decision Process (MDP) problem. We can use Q-learning or other reinforcement learning algorithms to\n",
    "solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal action for initial state: Arm 1\n",
      "Q-values for initial state: [2.29027634 1.20295999]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BayesianBanditQLearning:\n",
    "    def __init__(self, alpha1, beta1, alpha2, beta2, gamma, learning_rate=0.1, epsilon=0.1):\n",
    "        self.alpha1 = alpha1\n",
    "        self.beta1 = beta1\n",
    "        self.alpha2 = alpha2\n",
    "        self.beta2 = beta2\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.q_values = {}\n",
    "        \n",
    "    def get_state_key(self, alpha1, beta1, alpha2, beta2):\n",
    "        return (alpha1, beta1, alpha2, beta2)\n",
    "    \n",
    "    def get_q_value(self, state, action):\n",
    "        if state not in self.q_values:\n",
    "            self.q_values[state] = np.zeros(2)\n",
    "        return self.q_values[state][action]\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.randint(2)\n",
    "        else:\n",
    "            return np.argmax(self.q_values.get(state, np.zeros(2)))\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        next_max_q = np.max(self.q_values.get(next_state, np.zeros(2)))\n",
    "        \n",
    "        # Q-learning update rule\n",
    "        new_q = current_q + self.learning_rate * (reward + self.gamma * next_max_q - current_q)\n",
    "        \n",
    "        if state not in self.q_values:\n",
    "            self.q_values[state] = np.zeros(2)\n",
    "        self.q_values[state][action] = new_q\n",
    "\n",
    "    def train(self, episodes=1000, max_steps=100):\n",
    "        for _ in range(episodes):\n",
    "            # Reset state for new episode\n",
    "            alpha1, beta1 = self.alpha1, self.beta1\n",
    "            alpha2, beta2 = self.alpha2, self.beta2\n",
    "            \n",
    "            for step in range(max_steps):\n",
    "                state = self.get_state_key(alpha1, beta1, alpha2, beta2)\n",
    "                action = self.choose_action(state)\n",
    "                \n",
    "                # Generate reward based on Beta distribution\n",
    "                if action == 0:\n",
    "                    success_prob = alpha1 / (alpha1 + beta1)\n",
    "                    reward = 1 if np.random.random() < success_prob else 0\n",
    "                    if reward:\n",
    "                        alpha1 += 1\n",
    "                    else:\n",
    "                        beta1 += 1\n",
    "                else:\n",
    "                    success_prob = alpha2 / (alpha2 + beta2)\n",
    "                    reward = 1 if np.random.random() < success_prob else 0\n",
    "                    if reward:\n",
    "                        alpha2 += 1\n",
    "                    else:\n",
    "                        beta2 += 1\n",
    "                \n",
    "                reward = reward * (self.gamma ** step)\n",
    "                next_state = self.get_state_key(alpha1, beta1, alpha2, beta2)\n",
    "                \n",
    "                self.update(state, action, reward, next_state)\n",
    "\n",
    "# Test the Q-learning implementation\n",
    "ql = BayesianBanditQLearning(alpha1=1, beta1=1, alpha2=1, beta2=1, gamma=0.9)\n",
    "ql.train()\n",
    "\n",
    "# Get optimal policy for initial state\n",
    "initial_state = ql.get_state_key(1, 1, 1, 1)\n",
    "optimal_action = np.argmax(ql.q_values.get(initial_state, np.zeros(2)))\n",
    "print(f\"Optimal action for initial state: Arm {optimal_action + 1}\")\n",
    "print(f\"Q-values for initial state: {ql.q_values.get(initial_state, np.zeros(2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 The optimal policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy(N, gamma, true_theta, alpha, beta, max_exploration = 100):\n",
    "    rewards = np.zeros(N)\n",
    "    alpha = np.array(alpha)\n",
    "    beta = np.array(beta)\n",
    "    calculate_R(alpha[0], beta[0], alpha[1], beta[1], gamma, 0, max_exploration = 100)\n",
    "    \n",
    "    for t in range(N):\n",
    "        chosen_arm = 0 if policy[(alpha[0], beta[0], alpha[1], beta[1])] else 1\n",
    "        reward = np.random.rand() < true_theta[chosen_arm]\n",
    "        rewards[t] = reward * (gamma ** t)\n",
    "        alpha[chosen_arm] += reward\n",
    "        beta[chosen_arm] += 1 - reward\n",
    "\n",
    "    return np.sum(rewards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the optimal policy and compare its performance with the intuitive policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario 1: True probabilities = [0.85 0.9 ]\n",
      "Intuitive Average reward: 53.92\n",
      "Optimal Average reward: 54.14\n",
      "Regret Rate (Intuitive): 0.4009\n",
      "Regret Rate (Optimal): 0.3985\n",
      "Improvement: 0.40%\n",
      "\n",
      "Scenario 2: True probabilities = [0.6 0.8]\n",
      "Intuitive Average reward: 38.05\n",
      "Optimal Average reward: 38.02\n",
      "Regret Rate (Intuitive): 0.5244\n",
      "Regret Rate (Optimal): 0.5247\n",
      "Improvement: -0.07%\n",
      "\n",
      "Scenario 3: True probabilities = [0.95 0.85]\n",
      "Intuitive Average reward: 60.24\n",
      "Optimal Average reward: 60.18\n",
      "Regret Rate (Intuitive): 0.3659\n",
      "Regret Rate (Optimal): 0.3665\n",
      "Improvement: -0.11%\n",
      "\n",
      "Scenario 4: True probabilities = [0.5  0.55]\n",
      "Intuitive Average reward: 31.56\n",
      "Optimal Average reward: 31.69\n",
      "Regret Rate (Intuitive): 0.4262\n",
      "Regret Rate (Optimal): 0.4238\n",
      "Improvement: 0.42%\n"
     ]
    }
   ],
   "source": [
    "test_runs = 1000\n",
    "test_rewards_intuitive = np.zeros(test_runs)\n",
    "test_rewards_optimal = np.zeros(test_runs)\n",
    "N_short = 100\n",
    "gamma_close_to_1 = 0.99\n",
    "\n",
    "counter_alpha = [200, 1]\n",
    "counter_beta = [1, 1]\n",
    "# Different scenarios of true probabilities\n",
    "counter_true_thetas = [\n",
    "    np.array([0.85, 0.9]),   # Case 1: Second arm slightly better\n",
    "    np.array([0.6, 0.8]),    # Case 2: Second arm significantly better\n",
    "    np.array([0.95, 0.85]),  # Case 3: First arm better\n",
    "    np.array([0.5, 0.55])    # Case 4: Close probabilities\n",
    "]\n",
    "\n",
    "for scenario_idx, counter_true_theta in enumerate(counter_true_thetas, 1):\n",
    "    print(f\"\\nScenario {scenario_idx}: True probabilities = {counter_true_theta}\")\n",
    "    \n",
    "    for i in range(test_runs):\n",
    "        local_alpha = counter_alpha.copy()\n",
    "        local_beta = counter_beta.copy()\n",
    "        test_rewards_intuitive[i] = intuitive_policy(N_short, gamma_close_to_1, \n",
    "                                                   counter_true_theta, local_alpha, local_beta)\n",
    "\n",
    "    for i in range(test_runs):\n",
    "        local_alpha = counter_alpha.copy()\n",
    "        local_beta = counter_beta.copy()\n",
    "        test_rewards_optimal[i] = optimal_policy(N_short, gamma_close_to_1, \n",
    "                                               counter_true_theta, local_alpha, local_beta, 200)\n",
    "    \n",
    "    avg_r_intuitive = np.mean(test_rewards_intuitive)\n",
    "    avg_r_optimal = np.mean(test_rewards_optimal)\n",
    "    optimal_r = np.max(counter_true_theta) / (1 - gamma_close_to_1)\n",
    "    regret_rate_intuitive = 1 - avg_r_intuitive/optimal_r\n",
    "    regret_rate_optimal = 1 - avg_r_optimal/optimal_r\n",
    "    \n",
    "    print(f\"Intuitive Average reward: {avg_r_intuitive:.2f}\")\n",
    "    print(f\"Optimal Average reward: {avg_r_optimal:.2f}\")\n",
    "    print(f\"Regret Rate (Intuitive): {regret_rate_intuitive:.4f}\")\n",
    "    print(f\"Regret Rate (Optimal): {regret_rate_optimal:.4f}\")\n",
    "    print(f\"Improvement: {((avg_r_optimal - avg_r_intuitive)/avg_r_intuitive * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results presented above, we can conclude that the optimal policy significantly enhances performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further investigation: Let's adjust the hyperparameter 'max_exploration' to control the number of times we explore rather than exploit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_runs = 10000\n",
    "test_rewards_optimal = np.zeros(test_runs)\n",
    "N_short = 100\n",
    "gamma_close_to_1 = 0.99\n",
    "\n",
    "counter_alpha = [200, 1]\n",
    "counter_beta = [1, 1]\n",
    "counter_true_theta = np.array([0.85, 0.9])\n",
    "\n",
    "avg_rewards_per_exploration = []\n",
    "\n",
    "for max_exploration in [100, 300, 500]:\n",
    "    total_rewards = []\n",
    "\n",
    "    for i in range(test_runs):\n",
    "        local_alpha = counter_alpha.copy()\n",
    "        local_beta = counter_beta.copy()\n",
    "        test_rewards_optimal[i] = optimal_policy(N_short, gamma_close_to_1, counter_true_theta, local_alpha, local_beta, max_exploration)\n",
    "\n",
    "    avg_r_optimal = np.mean(test_rewards_optimal)\n",
    "    avg_rewards_per_exploration.append(avg_r_optimal)\n",
    "\n",
    "plt.plot([100, 300, 500], avg_rewards_per_exploration, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Max Exploration')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Average Reward for Different Max Exploration Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that increasing exploration leads to better results. Here’s our reasoning:  \n",
    "We can interpret the equations in Problem 3 as Bellman equations in dynamic programming, except that they lack a base case. The base case actually exists when $\\alpha, \\beta \\to \\infty$. To approximate this base case, we use a sufficiently large number. Consequently, the larger the number, the closer it is to infinity, and the solution becomes more accurate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
